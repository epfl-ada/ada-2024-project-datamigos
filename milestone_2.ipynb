{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2\n",
    "\n",
    "This notebook aims to preprocess our data, and estimate the feasibility of the different ideas we had during the first milestone, using data exploration and some preliminary analysis.\n",
    "\n",
    "- [Dataset description](#Dataset-description)\n",
    "- [Initial dataset preprocessing](#Data-preprocessing)\n",
    "    - [Characters dataset](#Characters-dataset) \n",
    "    - [Movies dataset](#Movies-dataset)\n",
    "    - [Plot summaries dataset](#Plot-summaries-dataset)\n",
    "- [External datasets](#External-Datasets)\n",
    "- [Data merging](#Data-Merging)\n",
    "    - [TMDb](#tmdb)\n",
    "    - [IMDb](#imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets description\n",
    "\n",
    "This project utilizes a rich collection of datasets encompassing movies, characters, and plot summaries. The primary datasets include:\n",
    "\n",
    "- **Characters Dataset** (`character.metadata.tsv`): Contains detailed metadata on movie characters and the actors portraying them. Key attributes include Wikipedia and Freebase IDs, movie release dates, character names, actor birthdates, genders, heights, ethnicities, and ages at the time of movie release.\n",
    "\n",
    "- **Movies Dataset** (`movie.metadata.tsv`) Includes comprehensive information about movies. It features data such as Wikipedia and Freebase IDs, movie names, release dates, box office revenues, runtimes, languages, countries, and genres.\n",
    "\n",
    "- **Plot Summaries Dataset** (`plot_summaries.text`): Offers a concise summary of movie plots, linked to movies through Wikipedia movie IDs.\n",
    "\n",
    "### External datasets\n",
    "\n",
    "We also use external datasets to enrich our data. More information about these datasets can be found in the [External datasets](#External-datasets) section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data/\"\n",
    "DATA_FOLDER_CMU = DATA_FOLDER + \"raw/MovieSummaries/\"\n",
    "DATA_FOLDER_TMDB = DATA_FOLDER + \"raw/TMDb/\"\n",
    "DATA_FOLDER_IMDB = DATA_FOLDER + \"raw/IMDb/\"\n",
    "\n",
    "CMU_CHARACTER = DATA_FOLDER_CMU + \"character.metadata.tsv\"\n",
    "CMU_MOVIE = DATA_FOLDER_CMU + \"movie.metadata.tsv\"\n",
    "PLOT_SUMMARIES = DATA_FOLDER_CMU + \"plot_summaries.txt\"\n",
    "\n",
    "TMDB_MOVIE = DATA_FOLDER_TMDB + \"movies_metadata.csv\"\n",
    "TMDB_KEYWORDS = DATA_FOLDER_TMDB + \"keywords.csv\"\n",
    "\n",
    "# https://datasets.imdbws.com/\n",
    "IMDB_AKA = DATA_FOLDER_IMDB + \"title.akas.tsv\"\n",
    "IMDB_BASIC = DATA_FOLDER_IMDB + \"title.basics.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characters dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_characters = pd.read_table(\n",
    "    CMU_CHARACTER,\n",
    "    names=[\n",
    "        \"wikipedia_id\",\n",
    "        \"freebase_id\",\n",
    "        \"release_date\",\n",
    "        \"character_name\",\n",
    "        \"actor_dob\",\n",
    "        \"actor_gender\",\n",
    "        \"actor_height\",\n",
    "        \"actor_ethnicity\",\n",
    "        \"actor_name\",\n",
    "        \"actor_age_at_movie_release\",\n",
    "        \"freebase_actor_map_id\",\n",
    "        \"freebase_character_id\",\n",
    "        \"freebase_actor_id\",\n",
    "    ],\n",
    ")\n",
    "df_characters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we can find some missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characters.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can identify from the output above that:\n",
    "- There are some *missing values*\n",
    "- Some *type are not exploitable* (e.g. the `release_date` and `actor_dob`  are `object`s, not exploitable dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Total amount of rows that contain a NaN value: \",\n",
    "    df_characters.isna().any(axis=1).sum(),\n",
    ")\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"nan_sum\": df_characters.isna().sum(),\n",
    "        \"nan_percentage\": df_characters.isna().mean() * 100,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concerning the *missing values* problem, we have 4 options: perform value imputation, not using the problematic features, dropping the rows or filling the missing values using external datasets.\n",
    "\n",
    "Now we'll take a look at the values and see if we can find some outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characters.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find interesting results:\n",
    "- How can an actors' height be 510m ? \n",
    "- How can an actor's age be negative ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release date and date of birth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tackle the type problem we can convert the `object` type to `datetime` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characters[\"release_date\"] = df_characters[\"release_date\"].apply(convert_to_datetime)\n",
    "df_characters[\"release_date\"] = pd.to_datetime(\n",
    "    df_characters[\"release_date\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "df_characters[\"actor_dob\"] = df_characters[\"actor_dob\"].apply(convert_to_datetime)\n",
    "df_characters[\"actor_dob\"] = pd.to_datetime(df_characters[\"actor_dob\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characters[df_characters[\"actor_height\"] > 2.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a little search on the internet, we found that for the 510.0m problem, the actor's height is 5'10\" (1.78m). We'll have to fix this value.\n",
    "Concerning the 180m problem, we can guess that the actor's height is 1.80m, but we can't find any source to confirm this (internet or other rows). We should drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characters.loc[df_characters[\"actor_height\"] == 510, \"actor_height\"] = 1.78\n",
    "df_characters.drop(\n",
    "    df_characters[df_characters[\"actor_height\"] > 2.5].index, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then take care of the age problem by removing the rows with negative age. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    df_characters.loc[(df_characters[\"actor_age_at_movie_release\"] < 0)].shape[0],\n",
    "    \"such rows will be removed\",\n",
    ")\n",
    "\n",
    "\n",
    "df_characters = df_characters[df_characters[\"actor_age_at_movie_release\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of actor born after the movie release\n",
    "df_characters[df_characters[\"actor_dob\"] > df_characters[\"release_date\"]].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows that have duplicates\n",
    "df_characters.drop_duplicates(\n",
    "    subset=[\"freebase_id\", \"freebase_actor_id\", \"freebase_character_id\"], inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the movies metadata\n",
    "df_movies = pd.read_table(\n",
    "    CMU_MOVIE,\n",
    "    names=[\n",
    "        \"wikipedia_id\",\n",
    "        \"freebase_id\",\n",
    "        \"title\",\n",
    "        \"release_date\",\n",
    "        \"revenue\",\n",
    "        \"runtime\",\n",
    "        \"languages\",\n",
    "        \"countries\",\n",
    "        \"genres\",\n",
    "    ],\n",
    "    header=None,\n",
    ")\n",
    "df_movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Total amount of rows that contain a NaN value: \",\n",
    "    df_movies.isna().any(axis=1).sum(),\n",
    ")\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"nan_sum\": df_movies.isna().sum(),\n",
    "        \"nan_percentage\": df_movies.isna().mean() * 100,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate row\n",
    "print(\"Check for duplicate entries:\")\n",
    "print(df_movies.duplicated().sum())\n",
    "\n",
    "# Check for duplicated row with same name\n",
    "print(\"Check for duplicate entries with title only:\")\n",
    "print(df_movies.duplicated(subset=[\"title\"]).sum())\n",
    "\n",
    "# Check for duplicated row with same name and date release\n",
    "print(\"Check for duplicate entries with title and date release:\")\n",
    "print(df_movies.duplicated(subset=[\"title\", \"release_date\"]).sum())\n",
    "\n",
    "# Check for duplicate row with same name and runtime\n",
    "print(\"Check for duplicate entries with title and movie runtime:\")\n",
    "print(df_movies.duplicated(subset=[\"title\", \"runtime\"]).sum())\n",
    "\n",
    "# Check for duplicate row with same wikipedia ID\n",
    "print(\"Check for duplicate entries with wikipedia ID:\")\n",
    "print(df_movies.duplicated(subset=[\"wikipedia_id\"]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some duplicate entries on the name, but the wikipedia ID is always unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output, we observe that:\n",
    "- There a problem with the `release_date` column.\n",
    "- The `runtime` column seems to have some outliers, with at least one movie with a runtime of 0, and one of 1 million minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release date\n",
    "\n",
    "We have a similar date problem as the one we had with the characters dataset. We'll fix it the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date strings to datetime objects\n",
    "df_movies[\"release_date\"] = df_movies[\"release_date\"].apply(convert_to_datetime)\n",
    "df_movies[\"release_date\"] = pd.to_datetime(df_movies[\"release_date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the movie release date\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Distribution of release date\")\n",
    "plt.xlabel(\"Release date\")\n",
    "plt.ylabel(\"Count\")\n",
    "df_movies.dropna(subset=[\"release_date\"])[\n",
    "    \"release_date\"\n",
    "].dt.year.sort_values().value_counts(sort=False).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"There are {len(df_movies[df_movies['release_date'] >= pd.to_datetime('2014')])} movies are after 2014\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that there are some outliers for `runtime`. We'll drop the rows with a `runtime` less or equal to 0 and greater than 500 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_shape = df_movies.shape[0]\n",
    "df_movies.drop(df_movies[df_movies[\"runtime\"] > 500].index, inplace=True)\n",
    "df_movies.drop(df_movies[df_movies[\"runtime\"] <= 0].index, inplace=True)\n",
    "print(f\"Have removed {old_shape - df_movies.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Log distribution of movie runtime\")\n",
    "plt.xlabel(\"Runtime\")\n",
    "plt.ylabel(\"Count (log scale)\")\n",
    "plt.yscale(\"log\")\n",
    "df_movies.dropna(subset=[\"runtime\"])[\"runtime\"].hist(bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `genres` feature is represented by a dict, we'll explode this column to have a row for each genre to plot them nicelly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of genres\n",
    "df_movies[\"genres\"] = df_movies.apply(lambda row: extract_list(row, \"genres\"), axis=1)\n",
    "\n",
    "# Replace empty lists by NaN\n",
    "df_movies[\"genres\"] = df_movies[\"genres\"].apply(lambda x: np.nan if len(x) == 0 else x)\n",
    "\n",
    "# Explode the genres\n",
    "df_movies_exploded = df_movies.explode(\"genres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of movie genres, for the top 20 genres\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Distribution of movie genres\")\n",
    "plt.xlabel(\"Movie genres\")\n",
    "plt.ylabel(\"Count\")\n",
    "df_movies_exploded[\"genres\"].value_counts().head(20).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries\n",
    "\n",
    "Similarly to the `genres` column, the `countries` column is a dict of countries. We'll explode this column to have a row for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of countries\n",
    "df_movies[\"countries\"] = df_movies.apply(\n",
    "    lambda row: extract_list(row, \"countries\"), axis=1\n",
    ")\n",
    "\n",
    "# Replace empty lists by NaN\n",
    "df_movies[\"countries\"] = df_movies[\"countries\"].apply(\n",
    "    lambda x: np.nan if len(x) == 0 else x\n",
    ")\n",
    "\n",
    "# Explode the countries\n",
    "df_movies_exploded = df_movies.explode(\"countries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of movie countries, for the top 20 countries\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Distribution of movie countries\")\n",
    "plt.xlabel(\"Movie countries\")\n",
    "plt.ylabel(\"Count\")\n",
    "df_movies_exploded[\"countries\"].value_counts().head(20).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that US movies represent the large majority of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Languages\n",
    "\n",
    "Similarly to the `genres` column, the `languages` column is a dict of languages. We'll explode this column to have a row for each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of languages\n",
    "df_movies[\"languages\"] = df_movies.apply(\n",
    "    lambda row: extract_list(row, \"languages\"), axis=1\n",
    ")\n",
    "\n",
    "# Replace empty lists by NaN\n",
    "df_movies[\"languages\"] = df_movies[\"languages\"].apply(\n",
    "    lambda x: np.nan if len(x) == 0 else x\n",
    ")\n",
    "\n",
    "# Explode the languages\n",
    "df_movies_exploded = df_movies.explode(\"languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of movie language, for the top 20 languages\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Distribution of movie language\")\n",
    "plt.xlabel(\"Movie language\")\n",
    "plt.ylabel(\"Count\")\n",
    "df_movies_exploded[\"languages\"].value_counts().head(20).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot summaries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the plot summaries\n",
    "df_plots = pd.read_table(\n",
    "    PLOT_SUMMARIES, names=[\"wikipedia_id\", \"plot_summary\"], header=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plots.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"There are {df_plots.duplicated(subset=['plot_summary']).sum()} duplicated plot summaries:\"\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(df_plots[df_plots.duplicated(subset=[\"plot_summary\"])])\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some movies with the same plot summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies[df_movies[\"wikipedia_id\"].isin(df[\"wikipedia_id\"])].sort_values(\n",
    "    by=[\"wikipedia_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to directly merge our movie dataframe with the one with the plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data for merging\n",
    "df_movies = preprocess_movie_data(df_movies)\n",
    "\n",
    "df_movies = df_movies.join(df_plots.set_index(\"wikipedia_id\"), on=\"wikipedia_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Datasets\n",
    "\n",
    "- [The Movies Dataset](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset) contains metadata for 45,000 films listed in the Full MovieLens Dataset, all of which were released on or before July 2017. We will use this dataset, specifically the movies_metadata.csv file, primarily to enrich the movie.metadata.tsv of the CMU movie dataset. Additionally, this dataset includes plot keywords (in the keywords.csv file), which could be helpful for analyzing and clustering movie plots.\n",
    "\n",
    "- [IMDB Non-Commercial Dataset](https://developer.imdb.com/non-commercial-datasets/) is a giant database containing over 50 Million movies from different regions, which allows us to complement our initial dataset specifically with movies created in the Soviet Union during the cold war. In addition, using the IMDB API and the IMDbPY Package, we can extract the plot to fix the issues of imbalance (The CMU Movie Summaries data being largely focused on the United States)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merging\n",
    "## TMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmdb_movies = pd.read_csv(\n",
    "    TMDB_MOVIE,\n",
    "    usecols=[\n",
    "        \"id\",\n",
    "        \"title\",\n",
    "        \"release_date\",\n",
    "        \"revenue\",\n",
    "        \"runtime\",\n",
    "        \"genres\",\n",
    "        \"production_countries\",\n",
    "        \"original_language\",\n",
    "        \"spoken_languages\",\n",
    "        \"overview\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "df_tmdb_keywords = pd.read_csv(TMDB_KEYWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data for merging\n",
    "df_tmdb_movies = preprocess_movie_data(df_tmdb_movies)\n",
    "\n",
    "# Merge the TMDB movies with keywords based on id\n",
    "df_tmdb_movies[\"id\"] = df_tmdb_movies[\"id\"].astype(int)\n",
    "df_tmdb_movies = pd.merge(df_tmdb_movies, df_tmdb_keywords, on=\"id\", how=\"left\")\n",
    "\n",
    "for column_name in [\"genres\", \"production_countries\", \"spoken_languages\", \"keywords\"]:\n",
    "    df_tmdb_movies[column_name] = df_tmdb_movies[column_name].apply(\n",
    "        lambda row: (\n",
    "            [item[\"name\"] for item in ast.literal_eval(row)]\n",
    "            if pd.notnull(row) and ast.literal_eval(row)\n",
    "            else np.nan\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Merge based on the title\n",
    "df_merged_movies = pd.merge(\n",
    "    df_movies,\n",
    "    df_tmdb_movies,\n",
    "    on=\"title\",\n",
    "    how=\"outer\",\n",
    "    suffixes=(\"_original\", \"_additional\"),\n",
    ")\n",
    "df_merged_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill as much missing values as possible\n",
    "for _, column_name in enumerate(df_merged_movies.columns):\n",
    "\n",
    "    if column_name in [\"release_date_original\", \"revenue_original\", \"runtime_original\"]:\n",
    "        # craft the additional column name\n",
    "        new_column_name = column_name[: -len(\"_original\")]\n",
    "        column_name_additional = new_column_name + \"_additional\"\n",
    "        # fill the missing values\n",
    "        df_merged_movies[new_column_name] = df_merged_movies[column_name].combine_first(\n",
    "            df_merged_movies[column_name_additional]\n",
    "        )\n",
    "        # drop the original and additional column\n",
    "        df_merged_movies = df_merged_movies.drop(\n",
    "            columns=[column_name, column_name_additional]\n",
    "        )\n",
    "\n",
    "df_merged_movies[\"genres_original\"] = df_merged_movies.apply(\n",
    "    lambda row: list(\n",
    "        set(\n",
    "            (row[\"genres_original\"] if isinstance(row[\"genres_original\"], list) else [])\n",
    "            + (\n",
    "                row[\"genres_additional\"]\n",
    "                if isinstance(row[\"genres_additional\"], list)\n",
    "                else []\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Replace empty lists by NaN\n",
    "df_merged_movies[\"genres_original\"] = df_merged_movies[\"genres_original\"].apply(\n",
    "    lambda x: np.nan if len(x) == 0 else x\n",
    ")\n",
    "\n",
    "df_merged_movies = df_merged_movies.rename(columns={\"genres_original\": \"genres\"})\n",
    "\n",
    "df_merged_movies[\"languages\"] = df_merged_movies.apply(\n",
    "    lambda row: list(\n",
    "        set(\n",
    "            (row[\"languages\"] if isinstance(row[\"languages\"], list) else [])\n",
    "            + (\n",
    "                row[\"spoken_languages\"]\n",
    "                if isinstance(row[\"spoken_languages\"], list)\n",
    "                else []\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Replace empty lists by NaN\n",
    "df_merged_movies[\"languages\"] = df_merged_movies[\"languages\"].apply(\n",
    "    lambda x: np.nan if len(x) == 0 else x\n",
    ")\n",
    "\n",
    "df_merged_movies[\"countries\"] = df_merged_movies.apply(\n",
    "    lambda row: list(\n",
    "        set(\n",
    "            (row[\"countries\"] if isinstance(row[\"countries\"], list) else [])\n",
    "            + (\n",
    "                row[\"production_countries\"]\n",
    "                if isinstance(row[\"production_countries\"], list)\n",
    "                else []\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Replace empty lists by NaN\n",
    "df_merged_movies[\"countries\"] = df_merged_movies[\"countries\"].apply(\n",
    "    lambda x: np.nan if len(x) == 0 else x\n",
    ")\n",
    "\n",
    "df_merged_movies = df_merged_movies.drop(\n",
    "    columns=[\"spoken_languages\", \"production_countries\", \"id\", \"genres_additional\"]\n",
    ")\n",
    "\n",
    "df_merged_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_movies.to_csv(DATA_FOLDER + \"/preprocessed/merged_movies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_akas = pd.read_csv(IMDB_AKA, sep=\"\\t\", usecols=[\"titleId\", \"title\", \"region\"])\n",
    "title_basics = pd.read_csv(\n",
    "    IMDB_BASIC,\n",
    "    sep=\"\\t\",\n",
    "    usecols=[\"tconst\", \"primaryTitle\", \"titleType\", \"startYear\", \"genres\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on the common column tconst\n",
    "imdb_movies = pd.merge(title_akas, title_basics, left_on=\"titleId\", right_on=\"tconst\")\n",
    "\n",
    "# Select only the columns we need and rename `titleId` to `tconst` for consistency\n",
    "imdb_movies = imdb_movies[\n",
    "    [\"tconst\", \"title\", \"primaryTitle\", \"region\", \"titleType\", \"startYear\", \"genres\"]\n",
    "]\n",
    "\n",
    "regions = [\n",
    "    \"SU\",\n",
    "    \"RU\",\n",
    "    \"UA\",\n",
    "    \"BY\",\n",
    "    \"KZ\",\n",
    "    \"UZ\",\n",
    "    \"GE\",\n",
    "    \"AM\",\n",
    "    \"AZ\",\n",
    "    \"LT\",\n",
    "    \"LV\",\n",
    "    \"EE\",\n",
    "    \"TM\",\n",
    "    \"KG\",\n",
    "    \"TJ\",\n",
    "    \"MD\",\n",
    "]\n",
    "\n",
    "soviet_movies = imdb_movies[\n",
    "    imdb_movies[\"region\"].fillna(\"\").str.contains(\"|\".join(regions), case=False)\n",
    "]\n",
    "\n",
    "soviet_movies = (\n",
    "    soviet_movies[soviet_movies[\"titleType\"] == \"movie\"]\n",
    "    .drop_duplicates(subset=\"primaryTitle\", keep=\"first\")\n",
    "    .drop(columns=[\"title\", \"titleType\"])\n",
    ")\n",
    "\n",
    "soviet_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B: You'll need to install IMDbPY if that's not already the case. Simply run `pip install IMDbPY` in your shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb import IMDb\n",
    "ia = IMDb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "\n",
    "    soviet_movies[\"plot\"] = list(\n",
    "        tqdm(\n",
    "            executor.map(get_plot_summary, soviet_movies[\"tconst\"]),\n",
    "            total=len(soviet_movies),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soviet_movies.to_csv(DATA_FOLDER + \"/preprocessed/samples_soviet_movies.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soviet_movies = pd.read_csv(\n",
    "    DATA_FOLDER + \"/preprocessed/soviet_movies.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    usecols=[\n",
    "        \"tconst\",\n",
    "        \"title\",\n",
    "        \"primaryTitle\",\n",
    "        \"region\",\n",
    "        \"titleType\",\n",
    "        \"startYear\",\n",
    "        \"genres\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "soviet_movies = soviet_movies.drop(columns=[\"title\", \"titleType\"]).rename(\n",
    "    columns={\"primaryTitle\": \"title\", \"startYear\": \"release_date\"}\n",
    ")\n",
    "\n",
    "\n",
    "soviet_movies[\"release_date\"] = pd.to_datetime(\n",
    "    soviet_movies[\"release_date\"], format=\"%Y\", errors=\"coerce\"\n",
    ")\n",
    "\n",
    "\n",
    "soviet_movies[\"genres\"] = soviet_movies[\"genres\"].apply(\n",
    "    lambda genres: genres.split(\",\")\n",
    ")\n",
    "soviet_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_movies = pd.merge(df_merged_movies, soviet_movies, on=\"title\", how=\"outer\", suffixes=(\"_original\", \"_additional\"))\n",
    "df_merged_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_movies[\"release_date_original\"] = df_merged_movies[\"release_date_original\"].combine_first(\n",
    "    df_merged_movies[\"release_date_additional\"]\n",
    ")\n",
    "\n",
    "\n",
    "df_merged_movies[\"genres_original\"] = df_merged_movies.apply(\n",
    "    lambda row: list(\n",
    "        set(\n",
    "            (row[\"genres_original\"] if isinstance(row[\"genres_original\"], list) else [])\n",
    "            + (\n",
    "                row[\"genres_additional\"]\n",
    "                if isinstance(row[\"genres_additional\"], list)\n",
    "                else []\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "\n",
    "# Replace empty lists by NaN\n",
    "\n",
    "\n",
    "df_merged_movies[\"genres_original\"] = df_merged_movies[\"genres_original\"].apply(\n",
    "    lambda x: np.nan if len(x) == 0 else x\n",
    ")\n",
    "\n",
    "\n",
    "df_merged_movies = df_merged_movies.rename(\n",
    "    columns={\"release_date_original\": \"release_date\", \"genres_original\": \"genres\"}\n",
    ")\n",
    "df_merged_movies = df_merged_movies.drop(columns=[\"release_date_additional\", \"genres_additional\"])\n",
    "df_merged_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_1 = len(df_merged_movies[df_merged_movies[\"release_date\"] > pd.to_datetime(\"1991\")])\n",
    "len_2 = len(df_merged_movies[df_merged_movies[\"release_date\"] >= pd.to_datetime(\"1947\")])\n",
    "print(f\"There are {len_2 - len_1} movies taking place during the cold war (1947-91)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are about {len(df_merged_movies[df_merged_movies['region'] == 'RU'])} movies from Russia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revenue = df_merged_movies[df_merged_movies['revenue'].notna()]\n",
    "print(f\"There are {len(df_revenue)} entries with revenue, {len(df_revenue[df_revenue['region'] == 'RU'])} are from Russia.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
